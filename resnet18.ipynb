{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, copy, numpy as np\n",
    "from utils.train_model import train_model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sgdhess import SGDHess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'tiny-imagenet-200'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18()\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "device = torch.device('cuda')\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer_ft = SGDHess(model_ft.parameters(), lr = 0.15, weight_decay = 1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_ft, [80, 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\hess\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 157/157, Loss: 98.77537536621094....Train Loss: 4.9561 Acc: 0.0372\n",
      "Val Loss: 6.2761 Acc: 0.0081\n",
      "Best Val Accuracy: 0.0081\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Iteration: 157/157, Loss: 128.69920349121094.5.Train Loss: 4.2993 Acc: 0.1059\n",
      "Val Loss: 8.3084 Acc: 0.0028\n",
      "Best Val Accuracy: 0.0081\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Iteration: 157/157, Loss: 122.6227798461914..4.Train Loss: 3.8474 Acc: 0.1654\n",
      "Val Loss: 8.1727 Acc: 0.0041\n",
      "Best Val Accuracy: 0.0081\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Iteration: 8/1563, Loss: 226.48585510253906."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_ft = train_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft, scheduler,\n",
    "                       num_epochs=15, create_graph=False) # set to true for sgdhess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
